{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eu5P61Lh3t6M"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import dill\n",
    "import contrastive\n",
    "from contrastive import utils as contrastive_utils\n",
    "from acme import specs\n",
    "import jax\n",
    "import numpy as np\n",
    "\n",
    "import imageio\n",
    "from base64 import b64encode\n",
    "from IPython.display import display, HTML\n",
    "import tempfile\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import gym\n",
    "from acme.wrappers import gym_wrapper\n",
    "\n",
    "import metaworld\n",
    "# from contrastive_rl import classifier_envs\n",
    "from acme.wrappers import gym_wrapper\n",
    "from acme.wrappers import step_limit\n",
    "# from contrastive_rl import classifier_utils\n",
    "# from metaworld.envs.mujoco.utils import rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yI8zuom2jF4-"
   },
   "outputs": [],
   "source": [
    "# Wasn't able to use the checkpoints that Ben shared since there were some structures\n",
    "# from Google's internal libaries. Kyle's checkpoints work though!\n",
    "filename = './checkpoints/learner/'  # <-- Of course, this will be different for you\n",
    "reader = tf.train.load_checkpoint(filename)\n",
    "params = reader.get_tensor('learner/.ATTRIBUTES/py_state')\n",
    "state = dill.loads(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pK2gNZ4AjH1p",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env, obs_dim = contrastive_utils.make_environment('fixed-goal-point_Cross', start_index=0, end_index=-1, seed=0)\n",
    "spec = specs.make_environment_spec(env)\n",
    "networks = contrastive.make_networks(spec, obs_dim,\n",
    "                             actor_min_std=1e-6,  # <-- Make sure this is the same value used for training.\n",
    "                             use_image_obs=False)\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "# @jax.jit\n",
    "def _act(obs, key):\n",
    "  dist_params = networks.policy_network.apply(\n",
    "    state.policy_params, obs[None])\n",
    "  key, rng = jax.random.split(key, 2)\n",
    "  # action = dist_params.mode()  # <-- Use this if you want to act deterministically\n",
    "  action = networks.sample(dist_params, rng)\n",
    "  return action[0], key\n",
    "\n",
    "ts = env.reset()\n",
    "_act(ts.observation, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.policy_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nuWxhIYjPPv"
   },
   "outputs": [],
   "source": [
    "# the video writer commands will have to change here. I'd probably recommend using\n",
    "# imageio. You just make a list of all the images, and then call imageio.mimsave(filename, image_list)\n",
    "\n",
    "for _ in range(10):\n",
    "  video_filename = '/tmp/video.mp4'\n",
    "  writer = []\n",
    "\n",
    "  vec = []\n",
    "  ts = env.reset()\n",
    "  env._goal_img = ts.observation.copy()\n",
    "  for t in tqdm.trange(50):\n",
    "    a, key = _act(ts.observation, key)\n",
    "    ts = env.step(a.to_py())\n",
    "    # use the following lines for image-based environments.\n",
    "#     s = ts.observation[:obs_dim]\n",
    "    g = ts.observation[obs_dim:]\n",
    "    img = env.render(mode='rgb_array')\n",
    "#     img = np.concatenate([\n",
    "#       s.reshape((64, 64, 3)),\n",
    "#       g.reshape((64, 64, 3))\n",
    "#     ], axis=1)\n",
    "    # for state-based environments, use the following\n",
    "    # img = env.render(mode='rgb_array'), or something like that\n",
    "    writer.append(img)\n",
    "    if ts.last():\n",
    "      break\n",
    "  imageio.mimsave('output.gif', writer)\n",
    "\n",
    "  mp4 = open('output.gif','rb').read()\n",
    "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "  html = HTML(\"\"\"\n",
    "  <video width=800 framerate=1 controls>\n",
    "        <source src=\"%s\" type=\"video/mp4\">\n",
    "  </video>\n",
    "  \"\"\" % data_url)\n",
    "  display(html)\n",
    "# Not sure if the _dist variable applies to a state based environment? Commenting for now\n",
    "  plt.plot(env.environment.environment.environment._dist)\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "visualization script.ipynb",
   "provenance": [
    {
     "file_id": "1om0pY4JfPQXzZHCIl7wnOChHfbYhRsfo",
     "timestamp": 1658855827303
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
