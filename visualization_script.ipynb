{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Eu5P61Lh3t6M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 00:57:00.848920: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sarthak/anaconda3/envs/contrastive_rl/lib/:/home/sarthak/.mujoco/mujoco200/bin\n",
      "2022-08-03 00:57:00.848950: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "Warning: FrankaKitchen failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'dm_control'\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "pybullet build time: May 20 2022 19:45:31\n",
      "/home/sarthak/anaconda3/envs/contrastive_rl/lib/python3.9/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import dill\n",
    "import contrastive\n",
    "from contrastive import utils as contrastive_utils\n",
    "from acme import specs\n",
    "import jax\n",
    "import numpy as np\n",
    "\n",
    "import imageio #<-- This is an internal google library, but imageio should be able to do similar things\n",
    "from base64 import b64encode\n",
    "from IPython.display import display, HTML\n",
    "import tempfile\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import gym\n",
    "from acme.wrappers import gym_wrapper\n",
    "\n",
    "import metaworld\n",
    "# from contrastive_rl import classifier_envs\n",
    "from acme.wrappers import gym_wrapper\n",
    "from acme.wrappers import step_limit\n",
    "# from contrastive_rl import classifier_utils\n",
    "# from metaworld.envs.mujoco.utils import rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yI8zuom2jF4-"
   },
   "outputs": [],
   "source": [
    "filename = './checkpoints/learner/'  # <-- Of course, this will be different for you\n",
    "reader = tf.train.load_checkpoint(filename)\n",
    "params = reader.get_tensor('learner/.ATTRIBUTES/py_state')\n",
    "state = dill.loads(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pK2gNZ4AjH1p",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthak/anaconda3/envs/contrastive_rl/lib/python3.9/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "WARNING:root:The use of `check_types` is deprecated and does not have any effect.\n",
      "WARNING:root:The use of `check_types` is deprecated and does not have any effect.\n",
      "WARNING:root:The use of `check_types` is deprecated and does not have any effect.\n",
      "WARNING:root:The use of `check_types` is deprecated and does not have any effect.\n",
      "WARNING:root:The use of `check_types` is deprecated and does not have any effect.\n",
      "WARNING:root:The use of `check_types` is deprecated and does not have any effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In here! fixed-goal-point_Cross Cross\n",
      "Inside the right IF ELSE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DeviceArray([ 1., -1.], dtype=float32),\n",
       " DeviceArray([4146024105,  967050713], dtype=uint32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env, obs_dim = contrastive_utils.make_environment('fixed-goal-point_Cross', start_index=0, end_index=-1, seed=0)\n",
    "spec = specs.make_environment_spec(env)\n",
    "networks = contrastive.make_networks(spec, obs_dim,\n",
    "                             actor_min_std=1e-6,  # <-- Make sure this is the same value used for training.\n",
    "                             use_image_obs=False)\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "@jax.jit\n",
    "def _act(obs, key):\n",
    "  dist_params = networks.policy_network.apply(\n",
    "    state.policy_params, obs[None])\n",
    "  key, rng = jax.random.split(key, 2)\n",
    "  # action = dist_params.mode()  # <-- Use this if you want to act deterministically\n",
    "  action = networks.sample(dist_params, rng)\n",
    "  return action[0], key\n",
    "\n",
    "ts = env.reset()\n",
    "_act(ts.observation, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Normal/~/linear', 'Normal/~/linear_1', 'mlp/~/linear_0', 'mlp/~/linear_1'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.policy_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7nuWxhIYjPPv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                     | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# use the following lines for image-based environments.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     s = ts.observation[:obs_dim]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     g \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39mobservation[obs_dim:]\n\u001b[0;32m---> 17\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrgb_array\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     img = np.concatenate([\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#       s.reshape((64, 64, 3)),\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#       g.reshape((64, 64, 3))\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     ], axis=1)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# for state-based environments, use the following\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# img = env.render(mode='rgb_array'), or something like that\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     writer\u001b[38;5;241m.\u001b[39mappend(img)\n",
      "File \u001b[0;32m~/anaconda3/envs/contrastive_rl/lib/python3.9/site-packages/gym/core.py:114\u001b[0m, in \u001b[0;36mEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124;03m\"\"\"Renders the environment.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    The set of supported modes varies per environment. (And some\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m                super(MyEnv, self).render(mode=mode) # just raise an exception\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# the video writer commands will have to change here. I'd probably recommend using\n",
    "# imageio. You just make a list of all the images, and then call imageio.mimsave(filename, image_list)\n",
    "\n",
    "for _ in range(10):\n",
    "  video_filename = '/tmp/video.mp4'\n",
    "  writer = []\n",
    "\n",
    "  vec = []\n",
    "  ts = env.reset()\n",
    "  env._goal_img = ts.observation.copy()\n",
    "  for t in tqdm.trange(50):\n",
    "    a, key = _act(ts.observation, key)\n",
    "    ts = env.step(a.to_py())\n",
    "    # use the following lines for image-based environments.\n",
    "#     s = ts.observation[:obs_dim]\n",
    "    g = ts.observation[obs_dim:]\n",
    "    img = env.render(mode='rgb_array')\n",
    "#     img = np.concatenate([\n",
    "#       s.reshape((64, 64, 3)),\n",
    "#       g.reshape((64, 64, 3))\n",
    "#     ], axis=1)\n",
    "    # for state-based environments, use the following\n",
    "    # img = env.render(mode='rgb_array'), or something like that\n",
    "    writer.append(img)\n",
    "    if ts.last():\n",
    "      break\n",
    "  imageio.mimsave('output.gif', writer)\n",
    "\n",
    "  mp4 = open(video_filename,'rb').read()\n",
    "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "  html = HTML(\"\"\"\n",
    "  <video width=800 framerate=1 controls>\n",
    "        <source src=\"%s\" type=\"video/mp4\">\n",
    "  </video>\n",
    "  \"\"\" % data_url)\n",
    "  display(html)\n",
    "  plt.plot(env.environment.environment.environment._dist)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "visualization script.ipynb",
   "provenance": [
    {
     "file_id": "1om0pY4JfPQXzZHCIl7wnOChHfbYhRsfo",
     "timestamp": 1658855827303
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
